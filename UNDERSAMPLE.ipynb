{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d41bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "import joblib\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf # Importado para tf.random.set_seed\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    # StratifiedKFold, # No se usa directamente, GridSearchCV lo maneja\n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV\n",
    ")\n",
    "\n",
    "# --- CONFIGURACIÓN DE HILOS DE TENSORFLOW ---\n",
    "\n",
    "try:\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    logging.info(\"TensorFlow inter-op parallelism threads set to 1.\")\n",
    "    logging.info(\"TensorFlow intra-op parallelism threads set to 1.\")\n",
    "except RuntimeError as e:\n",
    "    # Esto puede ocurrir si los hilos ya fueron configurados (ej. en un entorno interactivo como Jupyter)\n",
    "    logging.warning(f\"Could not set TensorFlow threading: {e}. This might be okay if already configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d0dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-23 13:49:14,704 INFO     =================================================\n",
      "2025-05-23 13:49:14,705 INFO     === Iniciando experimento: Undersample_scenario1 ===\n",
      "2025-05-23 13:49:14,705 INFO     Técnica: Random Under Sampling con Escalado Controlado\n",
      "2025-05-23 13:49:14,706 INFO     Output directory: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario1\n",
      "2025-05-23 13:49:14,707 INFO     =================================================\n",
      "\n",
      "=== Iniciando experimento: Undersample_scenario1 ===\n",
      "2025-05-23 13:49:15,967 INFO     Dataset cargado (sin escalar). Forma: (284807, 31). Clases: {0: 284315, 1: 492}\n",
      "2025-05-23 13:49:15,995 INFO     >> ESCENARIO 1: RandomUnderSample en TODO el dataset (sin escalar) -> Split -> Escalado Separado\n",
      "2025-05-23 13:49:16,034 INFO        RUS Scen1: Tamaño después de resample (antes de split y escalar): (984, 30), Distribución y_res: {0: 492, 1: 492}\n",
      "2025-05-23 13:49:16,037 INFO        RUS Scen1: Después de Split. X_train_raw: (787, 30), X_test_raw: (197, 30)\n",
      "2025-05-23 13:49:16,040 INFO        RUS Scen1: Después de Escalado. X_train_final: (787, 30), X_test_final: (197, 30)\n",
      "2025-05-23 13:49:16,040 INFO        → Tamaños finales para modelado. Train: (787, 30), Test: (197, 30)\n",
      "2025-05-23 13:49:16,041 INFO        → Distribución y_train_final: {1: 394, 0: 393}\n",
      "2025-05-23 13:49:16,042 INFO        → Distribución y_test_final: {0: 99, 1: 98}\n",
      "> Hyperparameters will be saved to: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario1\\hyperparameters.txt\n",
      "\n",
      "> Entrenando NN...\n",
      "2025-05-23 13:49:16,048 INFO     Entrenando NN...\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "2025-05-23 13:49:36,033 INFO       ✔ Scaler NN guardado: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario1\\Undersample_scenario1_nn_scaler.joblib\n",
      "2025-05-23 13:49:36,034 INFO       ✔ Modelo Keras NN guardado: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario1\\Undersample_scenario1_nn_keras_model.h5\n",
      "  ✔ Hiperparámetros (o estado de error) guardados para NN\n",
      "\n",
      "> Entrenando LOGREG...\n",
      "2025-05-23 13:49:36,035 INFO     Entrenando LOGREG...\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "2025-05-23 13:49:57,422 INFO       ✔ Modelo guardado: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario1\\Undersample_scenario1_logreg_best.joblib\n",
      "  ✔ Hiperparámetros (o estado de error) guardados para LOGREG\n",
      "\n",
      "> Entrenando SVM...\n",
      "2025-05-23 13:49:57,423 INFO     Entrenando SVM...\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "2025-05-23 13:50:00,452 INFO       ✔ Modelo guardado: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario1\\Undersample_scenario1_svm_best.joblib\n",
      "  ✔ Hiperparámetros (o estado de error) guardados para SVM\n",
      "\n",
      "> Entrenando RF...\n",
      "2025-05-23 13:50:00,453 INFO     Entrenando RF...\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "2025-05-23 13:51:10,590 INFO       ✔ Modelo guardado: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario1\\Undersample_scenario1_rf_best.joblib\n",
      "  ✔ Hiperparámetros (o estado de error) guardados para RF\n",
      "\n",
      "> Entrenando XGB...\n",
      "2025-05-23 13:51:10,592 INFO     Entrenando XGB...\n",
      "Fitting 4 folds for each of 432 candidates, totalling 1728 fits\n",
      "2025-05-23 13:54:01,190 INFO       ✔ Modelo guardado: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario1\\Undersample_scenario1_xgb_best.joblib\n",
      "  ✔ Hiperparámetros (o estado de error) guardados para XGB\n",
      "2025-05-23 13:54:01,192 INFO     Entrenamiento completo en 285.1s\n",
      "\n",
      "> Reports will be saved to: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario1\\classification_reports.txt\n",
      "\n",
      "> Evaluando NN...\n",
      "2025-05-23 13:54:01,193 INFO     Evaluando NN...\n",
      "NN ROC-AUC: 0.9844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Fraude     0.9307    0.9495    0.9400        99\n",
      "      Fraude     0.9479    0.9286    0.9381        98\n",
      "\n",
      "    accuracy                         0.9391       197\n",
      "   macro avg     0.9393    0.9390    0.9391       197\n",
      "weighted avg     0.9393    0.9391    0.9391       197\n",
      "\n",
      "  ✔ Reporte guardado para NN\n",
      "\n",
      "> Evaluando LOGREG...\n",
      "2025-05-23 13:54:01,288 INFO     Evaluando LOGREG...\n",
      "LOGREG ROC-AUC: 0.9881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Fraude     0.9423    0.9899    0.9655        99\n",
      "      Fraude     0.9892    0.9388    0.9634        98\n",
      "\n",
      "    accuracy                         0.9645       197\n",
      "   macro avg     0.9658    0.9643    0.9644       197\n",
      "weighted avg     0.9657    0.9645    0.9644       197\n",
      "\n",
      "  ✔ Reporte guardado para LOGREG\n",
      "\n",
      "> Evaluando SVM...\n",
      "2025-05-23 13:54:01,294 INFO     Evaluando SVM...\n",
      "SVM ROC-AUC: 0.9882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Fraude     0.9000    1.0000    0.9474        99\n",
      "      Fraude     1.0000    0.8878    0.9405        98\n",
      "\n",
      "    accuracy                         0.9442       197\n",
      "   macro avg     0.9500    0.9439    0.9440       197\n",
      "weighted avg     0.9497    0.9442    0.9440       197\n",
      "\n",
      "  ✔ Reporte guardado para SVM\n",
      "\n",
      "> Evaluando RF...\n",
      "2025-05-23 13:54:01,301 INFO     Evaluando RF...\n",
      "RF ROC-AUC: 0.9867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Fraude     0.9423    0.9899    0.9655        99\n",
      "      Fraude     0.9892    0.9388    0.9634        98\n",
      "\n",
      "    accuracy                         0.9645       197\n",
      "   macro avg     0.9658    0.9643    0.9644       197\n",
      "weighted avg     0.9657    0.9645    0.9644       197\n",
      "\n",
      "  ✔ Reporte guardado para RF\n",
      "\n",
      "> Evaluando XGB...\n",
      "2025-05-23 13:54:01,314 INFO     Evaluando XGB...\n",
      "XGB ROC-AUC: 0.9857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Fraude     0.9495    0.9495    0.9495        99\n",
      "      Fraude     0.9490    0.9490    0.9490        98\n",
      "\n",
      "    accuracy                         0.9492       197\n",
      "   macro avg     0.9492    0.9492    0.9492       197\n",
      "weighted avg     0.9492    0.9492    0.9492       197\n",
      "\n",
      "  ✔ Reporte guardado para XGB\n",
      "2025-05-23 13:54:01,325 INFO     === Fin experimento Undersample_scenario1 ===\n",
      "\n",
      "=== Fin experimento: Undersample_scenario1 ===\n",
      "2025-05-23 13:54:01,327 INFO     =================================================\n",
      "2025-05-23 13:54:01,327 INFO     === Iniciando experimento: Undersample_scenario2 ===\n",
      "2025-05-23 13:54:01,328 INFO     Técnica: Random Under Sampling con Escalado Controlado\n",
      "2025-05-23 13:54:01,329 INFO     Output directory: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario2\n",
      "2025-05-23 13:54:01,329 INFO     =================================================\n",
      "\n",
      "=== Iniciando experimento: Undersample_scenario2 ===\n",
      "2025-05-23 13:54:02,463 INFO     Dataset cargado (sin escalar). Forma: (284807, 31). Clases: {0: 284315, 1: 492}\n",
      "2025-05-23 13:54:02,492 INFO     >> ESCENARIO 2: Split del dataset (sin escalar) -> Escalado Separado -> RandomUnderSample (solo en train escalado)\n",
      "2025-05-23 13:54:02,611 INFO        RUS Scen2: Después de Split inicial. X_train_raw: (227845, 30), X_test_raw: (56962, 30)\n",
      "2025-05-23 13:54:02,655 INFO        RUS Scen2: Después de Escalado. X_train_scaled_for_rus: (227845, 30), X_test_final: (56962, 30)\n",
      "2025-05-23 13:54:02,685 INFO        RUS Scen2: Después de RUS en train. X_train_final: (788, 30), y_train_final dist: {0: 394, 1: 394}\n",
      "2025-05-23 13:54:02,686 INFO        → Tamaños finales para modelado. Train: (788, 30), Test: (56962, 30)\n",
      "2025-05-23 13:54:02,687 INFO        → Distribución y_train_final: {0: 394, 1: 394}\n",
      "2025-05-23 13:54:02,688 INFO        → Distribución y_test_final: {0: 56864, 1: 98}\n",
      "> Hyperparameters will be saved to: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario2\\hyperparameters.txt\n",
      "\n",
      "> Entrenando NN...\n",
      "2025-05-23 13:54:02,698 INFO     Entrenando NN...\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "2025-05-23 13:54:21,732 INFO       ✔ Scaler NN guardado: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario2\\Undersample_scenario2_nn_scaler.joblib\n",
      "2025-05-23 13:54:21,733 INFO       ✔ Modelo Keras NN guardado: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario2\\Undersample_scenario2_nn_keras_model.h5\n",
      "  ✔ Hiperparámetros (o estado de error) guardados para NN\n",
      "\n",
      "> Entrenando LOGREG...\n",
      "2025-05-23 13:54:21,734 INFO     Entrenando LOGREG...\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "2025-05-23 13:54:41,092 INFO       ✔ Modelo guardado: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario2\\Undersample_scenario2_logreg_best.joblib\n",
      "  ✔ Hiperparámetros (o estado de error) guardados para LOGREG\n",
      "\n",
      "> Entrenando SVM...\n",
      "2025-05-23 13:54:41,093 INFO     Entrenando SVM...\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "2025-05-23 13:54:44,073 INFO       ✔ Modelo guardado: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario2\\Undersample_scenario2_svm_best.joblib\n",
      "  ✔ Hiperparámetros (o estado de error) guardados para SVM\n",
      "\n",
      "> Entrenando RF...\n",
      "2025-05-23 13:54:44,074 INFO     Entrenando RF...\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "2025-05-23 13:55:52,822 INFO       ✔ Modelo guardado: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario2\\Undersample_scenario2_rf_best.joblib\n",
      "  ✔ Hiperparámetros (o estado de error) guardados para RF\n",
      "\n",
      "> Entrenando XGB...\n",
      "2025-05-23 13:55:52,824 INFO     Entrenando XGB...\n",
      "Fitting 4 folds for each of 432 candidates, totalling 1728 fits\n",
      "2025-05-23 13:58:36,325 INFO       ✔ Modelo guardado: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario2\\Undersample_scenario2_xgb_best.joblib\n",
      "  ✔ Hiperparámetros (o estado de error) guardados para XGB\n",
      "2025-05-23 13:58:36,326 INFO     Entrenamiento completo en 273.6s\n",
      "\n",
      "> Reports will be saved to: C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\\Undersample_scenario2\\classification_reports.txt\n",
      "\n",
      "> Evaluando NN...\n",
      "2025-05-23 13:58:36,327 INFO     Evaluando NN...\n",
      "NN ROC-AUC: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Fraude     0.9998    0.9854    0.9925     56864\n",
      "      Fraude     0.0955    0.8980    0.1727        98\n",
      "\n",
      "    accuracy                         0.9852     56962\n",
      "   macro avg     0.5477    0.9417    0.5826     56962\n",
      "weighted avg     0.9983    0.9852    0.9911     56962\n",
      "\n",
      "  ✔ Reporte guardado para NN\n",
      "\n",
      "> Evaluando LOGREG...\n",
      "2025-05-23 13:58:36,815 INFO     Evaluando LOGREG...\n",
      "LOGREG ROC-AUC: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Fraude     0.9999    0.9761    0.9878     56864\n",
      "      Fraude     0.0620    0.9184    0.1162        98\n",
      "\n",
      "    accuracy                         0.9760     56962\n",
      "   macro avg     0.5309    0.9472    0.5520     56962\n",
      "weighted avg     0.9982    0.9760    0.9863     56962\n",
      "\n",
      "  ✔ Reporte guardado para LOGREG\n",
      "\n",
      "> Evaluando SVM...\n",
      "2025-05-23 13:58:36,873 INFO     Evaluando SVM...\n",
      "SVM ROC-AUC: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Fraude     0.9998    0.9925    0.9962     56864\n",
      "      Fraude     0.1699    0.8878    0.2852        98\n",
      "\n",
      "    accuracy                         0.9923     56962\n",
      "   macro avg     0.5849    0.9401    0.6407     56962\n",
      "weighted avg     0.9984    0.9923    0.9949     56962\n",
      "\n",
      "  ✔ Reporte guardado para SVM\n",
      "\n",
      "> Evaluando RF...\n",
      "2025-05-23 13:58:38,469 INFO     Evaluando RF...\n",
      "RF ROC-AUC: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Fraude     0.9999    0.9642    0.9817     56864\n",
      "      Fraude     0.0423    0.9184    0.0809        98\n",
      "\n",
      "    accuracy                         0.9641     56962\n",
      "   macro avg     0.5211    0.9413    0.5313     56962\n",
      "weighted avg     0.9982    0.9641    0.9801     56962\n",
      "\n",
      "  ✔ Reporte guardado para RF\n",
      "\n",
      "> Evaluando XGB...\n",
      "2025-05-23 13:58:39,019 INFO     Evaluando XGB...\n",
      "XGB ROC-AUC: 0.9807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Fraude     0.9999    0.9592    0.9791     56864\n",
      "      Fraude     0.0377    0.9286    0.0725        98\n",
      "\n",
      "    accuracy                         0.9591     56962\n",
      "   macro avg     0.5188    0.9439    0.5258     56962\n",
      "weighted avg     0.9982    0.9591    0.9776     56962\n",
      "\n",
      "  ✔ Reporte guardado para XGB\n",
      "2025-05-23 13:58:39,115 INFO     === Fin experimento Undersample_scenario2 ===\n",
      "\n",
      "=== Fin experimento: Undersample_scenario2 ===\n",
      "Todos los experimentos RUS con escalado controlado han finalizado.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Configuración global\n",
    "# -------------------------------------------------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "LOG_FMT = \"%(asctime)s %(levelname)-8s %(message)s\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Funciones auxiliares\n",
    "# -------------------------------------------------------------------\n",
    "def setup_logging(log_path):\n",
    "    os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "    root_logger = logging.getLogger()\n",
    "    for handler in root_logger.handlers[:]:\n",
    "        root_logger.removeHandler(handler)\n",
    "        handler.close()\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=LOG_FMT,\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_path, mode='w'),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def load_and_prepare(csv_path): # YA NO ESCALA INTERNAMENTE\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.rename(columns={'Time':'Tiempo', 'Amount':'Cantidad', 'Class':'Clase'})\n",
    "    return df\n",
    "\n",
    "def run_scenario_rus_with_controlled_scaling(df_original_unscaled, scenario):\n",
    "    target_col_name = 'Clase'\n",
    "    X_original_unscaled = df_original_unscaled.drop(target_col_name, axis=1)\n",
    "    y_original = df_original_unscaled[target_col_name]\n",
    "    \n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_final, X_test_final, y_train_final, y_test_final = [pd.DataFrame(), pd.DataFrame(), pd.Series(dtype='float64'), pd.Series(dtype='float64')]\n",
    "\n",
    "\n",
    "    if scenario == 'scenario1':\n",
    "        # 1. Balance en TODO el dataset (df_original_unscaled)\n",
    "        logging.info(\">> ESCENARIO 1: RandomUnderSample en TODO el dataset (sin escalar) -> Split -> Escalado Separado\")\n",
    "        X_res_unscaled_np, y_res_np = rus.fit_resample(X_original_unscaled, y_original)\n",
    "        \n",
    "        X_res_unscaled = pd.DataFrame(X_res_unscaled_np, columns=X_original_unscaled.columns)\n",
    "        y_res = pd.Series(y_res_np, name=y_original.name)\n",
    "        logging.info(f\"   RUS Scen1: Tamaño después de resample (antes de split y escalar): {X_res_unscaled.shape}, Distribución y_res: {dict(y_res.value_counts())}\")\n",
    "\n",
    "        if X_res_unscaled.empty or y_res.empty:\n",
    "            logging.error(\"   RUS Scen1: X_res_unscaled o y_res vacíos después del balanceo. Abortando escenario.\")\n",
    "            return X_train_final, X_test_final, y_train_final, y_test_final\n",
    "\n",
    "\n",
    "        stratify_param_s1 = y_res if not y_res.empty and len(y_res.unique()) > 1 else None\n",
    "        X_train_raw, X_test_raw, y_train_final, y_test_final = train_test_split(\n",
    "            X_res_unscaled, y_res, test_size=0.2, stratify=stratify_param_s1, random_state=42\n",
    "        )\n",
    "        logging.info(f\"   RUS Scen1: Después de Split. X_train_raw: {X_train_raw.shape}, X_test_raw: {X_test_raw.shape}\")\n",
    "\n",
    "        if not X_train_raw.empty:\n",
    "            scaler_s1 = MinMaxScaler()\n",
    "            X_train_final = pd.DataFrame(scaler_s1.fit_transform(X_train_raw), columns=X_train_raw.columns, index=X_train_raw.index)\n",
    "            if not X_test_raw.empty:\n",
    "                X_test_final = pd.DataFrame(scaler_s1.transform(X_test_raw), columns=X_test_raw.columns, index=X_test_raw.index)\n",
    "            logging.info(f\"   RUS Scen1: Después de Escalado. X_train_final: {X_train_final.shape}, X_test_final: {X_test_final.shape if not X_test_final.empty else '(empty)'}\")\n",
    "        \n",
    "    else: # scenario2\n",
    "        logging.info(\">> ESCENARIO 2: Split del dataset (sin escalar) -> Escalado Separado -> RandomUnderSample (solo en train escalado)\")\n",
    "        stratify_param_s2_initial = y_original if not y_original.empty and len(y_original.unique()) > 1 else None\n",
    "        X_train_raw, X_test_raw, y_train_orig, y_test_final = train_test_split(\n",
    "            X_original_unscaled, y_original, stratify=stratify_param_s2_initial, test_size=0.2,  random_state=42 )\n",
    "        logging.info(f\"   RUS Scen2: Después de Split inicial. X_train_raw: {X_train_raw.shape}, X_test_raw: {X_test_raw.shape}\")\n",
    "\n",
    "        X_train_scaled_for_rus = pd.DataFrame()\n",
    "        # X_test_final ya se inicializó y se llenará aquí si X_test_raw no es vacío\n",
    "\n",
    "        if not X_train_raw.empty:\n",
    "            scaler_s2 = MinMaxScaler()\n",
    "            X_train_scaled_for_rus = pd.DataFrame(scaler_s2.fit_transform(X_train_raw), columns=X_train_raw.columns, index=X_train_raw.index)\n",
    "            if not X_test_raw.empty:\n",
    "                X_test_final = pd.DataFrame(scaler_s2.transform(X_test_raw), columns=X_test_raw.columns, index=X_test_raw.index)\n",
    "            logging.info(f\"   RUS Scen2: Después de Escalado. X_train_scaled_for_rus: {X_train_scaled_for_rus.shape}, X_test_final: {X_test_final.shape if not X_test_final.empty else '(empty)'}\")\n",
    "        \n",
    "        if not X_train_scaled_for_rus.empty and not y_train_orig.empty:\n",
    "            X_train_res_np, y_train_res_np = rus.fit_resample(X_train_scaled_for_rus, y_train_orig)\n",
    "            X_train_final = pd.DataFrame(X_train_res_np, columns=X_train_scaled_for_rus.columns)\n",
    "            y_train_final = pd.Series(y_train_res_np, name=y_train_orig.name)\n",
    "            logging.info(f\"   RUS Scen2: Después de RUS en train. X_train_final: {X_train_final.shape}, y_train_final dist: {dict(y_train_final.value_counts() if not y_train_final.empty else {})}\")\n",
    "        else: # Si X_train_scaled_for_rus o y_train_orig son vacíos\n",
    "            X_train_final = X_train_scaled_for_rus # Pasa el (posiblemente vacío) X_train escalado\n",
    "            y_train_final = y_train_orig # Pasa el y_train original\n",
    "\n",
    "    logging.info(f\"   → Tamaños finales para modelado. Train: {X_train_final.shape if not X_train_final.empty else '(empty)'}, Test: {X_test_final.shape if not X_test_final.empty else '(empty)'}\")\n",
    "    if not (y_train_final is None or y_train_final.empty):\n",
    "        logging.info(f\"   → Distribución y_train_final: {dict(y_train_final.value_counts())}\")\n",
    "    else:\n",
    "        logging.warning(\"   → y_train_final está vacío o es None.\")\n",
    "    if not (y_test_final is None or y_test_final.empty):\n",
    "        logging.info(f\"   → Distribución y_test_final: {dict(y_test_final.value_counts())}\")\n",
    "    else:\n",
    "        logging.warning(\"   → y_test_final está vacío o es None.\")\n",
    "        \n",
    "    return X_train_final, X_test_final, y_train_final, y_test_final\n",
    "\n",
    "\n",
    "def build_nn_model(n_inputs, learning_rate=0.001, dropout_rate=0.5):\n",
    "    # ... (sin cambios, como lo tenías)\n",
    "    model = Sequential([\n",
    "        Dense(32, input_shape=(n_inputs,), activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_and_save_models(X_train, y_train, exp_name, output_dir):\n",
    "    # ... (sin cambios, como lo tenías, incluyendo el ImbPipeline con MinMaxScaler)\n",
    "    hyper_file = os.path.join(output_dir, 'hyperparameters.txt')\n",
    "    with open(hyper_file, 'w') as hf:\n",
    "        hf.write(f\"Hyperparameters for experiment {exp_name}\\n\")\n",
    "        hf.write(\"=\"*60 + \"\\n\\n\")\n",
    "    print(f\"> Hyperparameters will be saved to: {hyper_file}\")\n",
    "\n",
    "    if X_train.empty or X_train.shape[1] == 0:\n",
    "        logging.error(f\"X_train está vacío o no tiene características ANTES de entrenar modelos para {exp_name}. Saltando entrenamiento.\")\n",
    "        return {}\n",
    "\n",
    "    n_inputs = X_train.shape[1]\n",
    "\n",
    "    # KerasClassifier como lo tenías, pero verbose=0 y callbacks en fit_params\n",
    "    nn_wrapper = KerasClassifier(\n",
    "        build_fn=build_nn_model,\n",
    "        n_inputs=n_inputs,\n",
    "        verbose=0, \n",
    "    )\n",
    "\n",
    "    specs = { # Usando tus specs originales\n",
    "        'nn': (\n",
    "            nn_wrapper,\n",
    "            {\n",
    "                'clf__learning_rate':    [0.001, 0.0001],\n",
    "                'clf__dropout_rate':     [0.3],\n",
    "                'clf__batch_size':       [16, 32, 64],\n",
    "                'clf__epochs':           [50],\n",
    "                # 'clf__validation_split':[0.1] # Se pasa en fit_params\n",
    "            }\n",
    "        ),\n",
    "        'logreg': (\n",
    "            LogisticRegression(random_state=42, max_iter=1000), # Sin class_weight, ya que RUS balancea\n",
    "            {'clf__penalty': ['l1','l2'], 'clf__C': [0.001, 0.01, 0.7, 0.1, 0.2, 1, 10, 100, 1000], 'clf__solver': ['liblinear']}\n",
    "        ),\n",
    "        'svm': (\n",
    "            SVC(probability=True, random_state=42), # Sin class_weight\n",
    "            {'clf__C': [0.5, 0.7, 0.9, 1, 1.5], 'clf__kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n",
    "        ),\n",
    "        'rf': (\n",
    "            RandomForestClassifier(random_state=42), # Sin class_weight\n",
    "            {'clf__n_estimators': [50, 100, 200], 'clf__max_depth': [None, 10, 20, 30], 'clf__min_samples_split': [2, 5, 10], 'clf__min_samples_leaf': [1, 2, 4]}\n",
    "        ),\n",
    "        'xgb': (\n",
    "            XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "            {\n",
    "                'clf__n_estimators': [50, 100, 200],\n",
    "                'clf__max_depth': [3, 5, 7, 10],\n",
    "                'clf__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "                'clf__subsample': [0.7, 0.8, 0.9],\n",
    "                'clf__colsample_bytree': [0.7, 0.8, 1]\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "\n",
    "    best_models = {}\n",
    "    for name, (clf, param_grid) in specs.items():\n",
    "        print(f\"\\n> Entrenando {name.upper()}...\")\n",
    "        logging.info(f\"Entrenando {name.upper()}...\")\n",
    "\n",
    "        pipe = ImbPipeline([\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('clf', clf)\n",
    "        ])\n",
    "        \n",
    "        y_train_processed = y_train.astype(int)\n",
    "\n",
    "        fit_params = {}\n",
    "\n",
    "\n",
    "        n_cv_splits = 4 \n",
    "        # Lógica de ajuste de CV si es necesario\n",
    "        if len(y_train_processed.unique()) > 1:\n",
    "            min_class_count = min(y_train_processed.value_counts())\n",
    "            if min_class_count < n_cv_splits :\n",
    "                logging.warning(f\"Clase minoritaria en y_train para {name} tiene {min_class_count} muestras, menos que cv={n_cv_splits}. Ajustando cv.\")\n",
    "                n_cv_splits = max(2, min_class_count) if min_class_count >=2 else 1\n",
    "                if n_cv_splits == 1: # No se puede hacer CV con 1 split\n",
    "                    logging.error(f\"No se puede realizar CV para {name} con n_splits=1. Saltando este modelo.\")\n",
    "                    best_models[name] = None\n",
    "                    with open(hyper_file, 'a') as hf:\n",
    "                        hf.write(f\"{name.upper()} best params: CV SKIPPED (n_splits=1)\\n\")\n",
    "                        hf.write(f\"{name.upper()} best CV ROC-AUC: N/A\\n\\n\")\n",
    "                    continue # Saltar al siguiente modelo\n",
    "        if X_train.shape[0] < n_cv_splits :\n",
    "             logging.warning(f\"No hay suficientes muestras en X_train ({X_train.shape[0]}) para CV con {n_cv_splits} splits en {name}. Ajustando cv.\")\n",
    "             n_cv_splits = max(2, X_train.shape[0]) if X_train.shape[0] >=2 else 1\n",
    "             if n_cv_splits == 1:\n",
    "                logging.error(f\"No se puede realizar CV para {name} con n_splits=1 (pocas muestras). Saltando este modelo.\")\n",
    "                best_models[name] = None\n",
    "                with open(hyper_file, 'a') as hf:\n",
    "                    hf.write(f\"{name.upper()} best params: CV SKIPPED (n_splits=1)\\n\")\n",
    "                    hf.write(f\"{name.upper()} best CV ROC-AUC: N/A\\n\\n\")\n",
    "                continue\n",
    "        \n",
    "        cv_obj = StratifiedKFold( n_splits=min(4, min_class_count), shuffle=True, random_state=42)\n",
    "\n",
    "        grid = GridSearchCV(\n",
    "            pipe, param_grid,\n",
    "            cv=cv_obj, scoring='roc_auc',\n",
    "            n_jobs=1, verbose=1, refit=True, error_score='raise' \n",
    "        )\n",
    "        \n",
    "        best_estimator_for_model = None\n",
    "        try:\n",
    "            grid.fit(X_train, y_train_processed)\n",
    "            best_estimator_for_model = grid.best_estimator_\n",
    "            best_params_str = str(grid.best_params_)\n",
    "            best_score_str = f\"{grid.best_score_:.4f}\"\n",
    "        except ValueError as ve:\n",
    "            logging.error(f\"ValueError (posiblemente CV) en GridSearchCV para {name}: {ve}\", exc_info=True)\n",
    "            best_params_str = \"Error en CV\"\n",
    "            best_score_str = \"Error en CV\"\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error general en GridSearchCV para {name}: {e}\", exc_info=True)\n",
    "            best_params_str = \"Error general\"\n",
    "            best_score_str = \"Error general\"\n",
    "\n",
    "        if best_estimator_for_model:\n",
    "            if name == 'nn':\n",
    "                best_pipeline_nn = best_estimator_for_model\n",
    "                scaler_nn = best_pipeline_nn.named_steps['scaler']\n",
    "  \n",
    "                if hasattr(best_pipeline_nn.named_steps['clf'], 'model_') :\n",
    "                    keras_model_nn = best_pipeline_nn.named_steps['clf'].model_\n",
    "                elif hasattr(best_pipeline_nn.named_steps['clf'], 'model'): \n",
    "                    keras_model_nn = best_pipeline_nn.named_steps['clf'].model\n",
    "                else:\n",
    "                    logging.error(f\"No se pudo encontrar el atributo del modelo Keras para {name}\")\n",
    "                    best_models[name] = None\n",
    "                    with open(hyper_file, 'a') as hf:\n",
    "                        hf.write(f\"{name.upper()} best params: {best_params_str} (Error Keras model attr)\\n\")\n",
    "                        hf.write(f\"{name.upper()} best CV ROC-AUC: {best_score_str}\\n\\n\")\n",
    "                    continue\n",
    "\n",
    "                scaler_path = os.path.join(output_dir, f\"{exp_name}_{name}_scaler.joblib\")\n",
    "                keras_model_path = os.path.join(output_dir, f\"{exp_name}_{name}_keras_model.h5\")\n",
    "                joblib.dump(scaler_nn, scaler_path)\n",
    "                keras_model_nn.save(keras_model_path)\n",
    "                logging.info(f\"  ✔ Scaler NN guardado: {scaler_path}\")\n",
    "                logging.info(f\"  ✔ Modelo Keras NN guardado: {keras_model_path}\")\n",
    "                best_models[name] = (scaler_path, keras_model_path)\n",
    "            else:\n",
    "                model_path = os.path.join(output_dir, f\"{exp_name}_{name}_best.joblib\")\n",
    "                joblib.dump(best_estimator_for_model, model_path)\n",
    "                logging.info(f\"  ✔ Modelo guardado: {model_path}\")\n",
    "                best_models[name] = best_estimator_for_model\n",
    "        else:\n",
    "            best_models[name] = None\n",
    "            logging.warning(f\"No se pudo obtener best_estimator para {name}.\")\n",
    "\n",
    "        with open(hyper_file, 'a') as hf:\n",
    "            hf.write(f\"{name.upper()} best params: {best_params_str}\\n\")\n",
    "            hf.write(f\"{name.upper()} best CV ROC-AUC: {best_score_str}\\n\\n\")\n",
    "        print(f\"  ✔ Hiperparámetros (o estado de error) guardados para {name.upper()}\")\n",
    "    \n",
    "    return {k:v for k,v in best_models.items() if v is not None}\n",
    "\n",
    "\n",
    "def evaluate_and_save_reports(models, X_test, y_test, output_dir):\n",
    "    # ... (sin cambios, como lo tenías)\n",
    "    report_file = os.path.join(output_dir, \"classification_reports.txt\")\n",
    "    with open(report_file, \"w\") as rf:\n",
    "        rf.write(f\"Classification reports for {os.path.basename(output_dir)}\\n\")\n",
    "        rf.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    print(f\"\\n> Reports will be saved to: {report_file}\")\n",
    "\n",
    "    if X_test.empty or y_test.empty:\n",
    "        logging.error(\"X_test o y_test están vacíos. No se pueden generar reportes.\")\n",
    "        print(\"X_test o y_test están vacíos. Saltando evaluación.\")\n",
    "        return\n",
    "\n",
    "    y_test_processed = y_test.astype(int)\n",
    "\n",
    "    for name, model_or_paths in models.items():\n",
    "        print(f\"\\n> Evaluando {name.upper()}...\")\n",
    "        logging.info(f\"Evaluando {name.upper()}...\")\n",
    "        y_pred, y_prob = None, None\n",
    "\n",
    "        try:\n",
    "            if name == \"nn\":\n",
    "                scaler_path, keras_model_path = model_or_paths\n",
    "                scaler_loaded = joblib.load(scaler_path)\n",
    "                keras_model = load_model(keras_model_path, compile=False)\n",
    "                X_test_for_eval = scaler_loaded.transform(X_test)\n",
    "                y_prob_all_classes = keras_model.predict(X_test_for_eval)\n",
    "                y_prob = y_prob_all_classes[:, 1]\n",
    "                y_pred = np.argmax(y_prob_all_classes, axis=1)\n",
    "            else:\n",
    "                model_pipeline = model_or_paths\n",
    "                y_prob_all_classes = model_pipeline.predict_proba(X_test)\n",
    "                if y_prob_all_classes.shape[1] == 2:\n",
    "                    y_prob = y_prob_all_classes[:, 1]\n",
    "                    y_pred = model_pipeline.predict(X_test)\n",
    "                else:\n",
    "                    logging.error(f\"Forma inesperada de y_prob_all_classes para {name}: {y_prob_all_classes.shape}\")\n",
    "                    y_prob = np.zeros(len(y_test_processed))\n",
    "                    y_pred = np.zeros(len(y_test_processed))\n",
    "\n",
    "            auc = float('nan')\n",
    "            report_str = \"N/A\"\n",
    "\n",
    "            if y_pred is not None and y_prob is not None:\n",
    "                if len(np.unique(y_test_processed)) < 2 :\n",
    "                    logging.warning(f\"Solo una clase presente en y_test para {name}. ROC-AUC no es calculable.\")\n",
    "                elif len(y_prob) == 0:\n",
    "                     logging.warning(f\"y_prob está vacío para {name}. ROC-AUC no es calculable.\")\n",
    "                else:\n",
    "                    try:\n",
    "                        auc = roc_auc_score(y_test_processed, y_prob)\n",
    "                        if len(np.unique(y_pred)) < 2 and len(np.unique(y_test_processed)) >=2 :\n",
    "                            logging.warning(f\"Todas las predicciones son de una sola clase para {name}, pero y_test tiene variabilidad. ROC-AUC: {auc:.4f}\")\n",
    "                    except ValueError as e_auc:\n",
    "                        logging.error(f\"Error al calcular ROC-AUC para {name}: {e_auc}. y_test unique: {np.unique(y_test_processed)}, y_prob (first 5 unique): {np.unique(y_prob[:5]) if len(y_prob)>0 else 'empty'}\")\n",
    "                report_str = classification_report(\n",
    "                    y_test_processed, y_pred,\n",
    "                    target_names=[\"No Fraude\", \"Fraude\"],\n",
    "                    digits=4,\n",
    "                    zero_division=0\n",
    "                )\n",
    "            else:\n",
    "                logging.error(f\"Predicciones (y_pred o y_prob) no generadas para {name}.\")\n",
    "\n",
    "            print(f\"{name.upper()} ROC-AUC: {auc:.4f}\\n{report_str}\")\n",
    "            with open(report_file, \"a\") as rf:\n",
    "                rf.write(f\"{name.upper()} ROC-AUC: {auc:.4f}\\n\")\n",
    "                rf.write(report_str + \"\\n\")\n",
    "                rf.write(\"-\" * 60 + \"\\n\")\n",
    "            print(f\"  ✔ Reporte guardado para {name.upper()}\")\n",
    "        \n",
    "        except Exception as e_eval:\n",
    "            logging.error(f\"Error durante la evaluación de {name} en {output_dir}: {e_eval}\", exc_info=True)\n",
    "            print(f\"Error durante la evaluación de {name}: {e_eval}\")\n",
    "            with open(report_file, \"a\") as rf:\n",
    "                rf.write(f\"{name.upper()} - ERROR EN EVALUACIÓN: {e_eval}\\n{'-'*60}\\n\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Main\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # --- BLOQUE MAIN RESTAURADO A TU ORIGINAL ---\n",
    "    CSV_PATH    = \"C:/Users/saave/Desktop/Master_Thesis/Credit_card_data/creditcard.csv\"\n",
    "    BASE_OUTPUT = \"C:/Users/saave/Desktop/data_balance/Result_UNDERSAMPLE\"\n",
    "    technique   = \"Undersample\" \n",
    "    # --- FIN BLOQUE MAIN RESTAURADO ---\n",
    "\n",
    "    for scenario in [\"scenario1\", \"scenario2\"]:\n",
    "        exp_name   = f\"{technique}_{scenario}\" # Usa tu variable 'technique' original\n",
    "        output_dir = os.path.join(BASE_OUTPUT, exp_name) # Usa tu BASE_OUTPUT original\n",
    "        log_file   = os.path.join(output_dir, f\"run_{exp_name}.log\") # Nombre de log único\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        setup_logging(log_file)\n",
    "        \n",
    "        logging.info(f\"=================================================\")\n",
    "        logging.info(f\"=== Iniciando experimento: {exp_name} ===\")\n",
    "        logging.info(f\"Técnica: Random Under Sampling con Escalado Controlado\") # Descripción actualizada\n",
    "        logging.info(f\"Output directory: {output_dir}\")\n",
    "        logging.info(f\"=================================================\")\n",
    "        print(f\"\\n=== Iniciando experimento: {exp_name} ===\")\n",
    "\n",
    "        df_original = load_and_prepare(CSV_PATH)\n",
    "        logging.info(f\"Dataset cargado (sin escalar). Forma: {df_original.shape}. Clases: {dict(df_original['Clase'].value_counts())}\")\n",
    "\n",
    "        if df_original.shape[0] < 10:\n",
    "            logging.error(f\"Dataset con muy pocas filas ({df_original.shape[0]}). Abortando {exp_name}.\")\n",
    "            continue\n",
    "        class_counts = df_original['Clase'].value_counts()\n",
    "        if len(class_counts) < 2 or class_counts.get(0,0) == 0 or class_counts.get(1,0) == 0:\n",
    "            logging.error(f\"Dataset no tiene ambas clases o una clase está vacía: {class_counts.to_dict()}. Abortando {exp_name}.\")\n",
    "            continue\n",
    "\n",
    "        # Llamar a la función de escenario modificada\n",
    "        # (He renombrado la función a run_scenario_rus_with_controlled_scaling para claridad interna,\n",
    "        # pero puedes volver a llamarla run_scenario si prefieres y actualizar la llamada aquí)\n",
    "        X_train, X_test, y_train, y_test = run_scenario_rus_with_controlled_scaling(df_original.copy(), scenario)\n",
    "\n",
    "        if X_train.empty or y_train.empty:\n",
    "            logging.error(f\"X_train o y_train vacíos para {exp_name} DESPUÉS de run_scenario. Saltando entrenamiento.\")\n",
    "            continue\n",
    "        if len(y_train.value_counts()) < 1:\n",
    "            logging.warning(f\"y_train no tiene muestras para {exp_name}. El entrenamiento podría fallar.\")\n",
    "        elif len(y_train.value_counts()) < 2:\n",
    "             logging.warning(f\"y_train tiene solo una clase para {exp_name}. GridSearchCV se adaptará o podría fallar.\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        models = train_and_save_models(X_train, y_train, exp_name, output_dir)\n",
    "        logging.info(f\"Entrenamiento completo en {time.time() - start_time:.1f}s\")\n",
    "\n",
    "        if not models:\n",
    "            logging.warning(f\"No se entrenaron modelos exitosamente para {exp_name}. Saltando evaluación.\")\n",
    "        else:\n",
    "            if X_test is not None and not X_test.empty and y_test is not None and not y_test.empty:\n",
    "                 evaluate_and_save_reports(models, X_test, y_test, output_dir)\n",
    "            else:\n",
    "                logging.warning(f\"X_test o y_test están vacíos para {exp_name} DESPUÉS de run_scenario. Saltando evaluación.\")\n",
    "\n",
    "        logging.info(f\"=== Fin experimento {exp_name} ===\\n\")\n",
    "        print(f\"=== Fin experimento: {exp_name} ===\")\n",
    "\n",
    "    print(\"Todos los experimentos RUS con escalado controlado han finalizado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
